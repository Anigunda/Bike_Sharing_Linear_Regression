{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5O3clnlHjqp"
      },
      "source": [
        "# **Multiple Linear Regression**\n",
        "## **Bike Sharing Assignment**\n",
        "\n",
        "#### Problem Statement:\n",
        "\n",
        "A bike-sharing system is a service in which bikes are made available for shared use to individuals on a short term basis for a price or free. Many bike share systems allow people to borrow a bike from a \"dock\" which is usually computer-controlled wherein the user enters the payment information, and the system unlocks it. This bike can then be returned to another dock belonging to the same system.\n",
        "\n",
        "\n",
        "A US bike-sharing provider BikeIndia has recently suffered considerable dips in their revenues due to the ongoing Corona pandemic. The company is finding it very difficult to sustain in the current market scenario. So, it has decided to come up with a mindful business plan to be able to accelerate its revenue as soon as the ongoing lockdown comes to an end, and the economy restores to a healthy state.\n",
        "\n",
        "\n",
        "In such an attempt, **BikeIndia** aspires to understand the demand for shared bikes among the people after this ongoing quarantine situation ends across the nation due to Covid-19. They have planned this to prepare themselves to cater to the people's needs once the situation gets better all around and stand out from other service providers and make huge profits.\n",
        "\n",
        "\n",
        "They have contracted a consulting company to understand the factors on which the demand for these shared bikes depends. Specifically, they want to understand the factors affecting the demand for these shared bikes in the American market. The company wants to know:\n",
        "\n",
        "Which variables are significant in predicting the demand for shared bikes.\n",
        "How well those variables describe the bike demands\n",
        "Based on various meteorological surveys and people's styles, the service provider firm has gathered a large dataset on daily bike demands across the American market based on some factors.\n",
        "\n",
        "#### Business Goal:\n",
        "\n",
        "We are required to model the demand for shared bikes with the available independent variables. It will be used by the management to understand how exactly the demands vary with different features. They can accordingly manipulate the business strategy to meet the demand levels and meet the customer's expectations. Further, the model will be a good way for management to understand the demand dynamics of a new market.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### Data Dictionary\n",
        "- **instant:** Record index.\n",
        "- **dteday:** Date in `dd-mm-yyyy` format.\n",
        "- **season:** Season of the year (1 = Spring, 2 = Summer, 3 = Fall, 4 = Winter).\n",
        "- **yr:** Year (0 = 2018, 1 = 2019).\n",
        "- **mnth:** Month of the year (1 = January, ..., 12 = December).\n",
        "- **holiday:** Indicates whether the day is a holiday (1 = Holiday, 0 = Not a Holiday).\n",
        "- **weekday:** Day of the week (0 = Sunday, ..., 6 = Saturday).\n",
        "- **workingday:** Indicates whether the day is a working day (1 = Working Day, 0 = Weekend or Holiday).\n",
        "- **weathersit:** Weather situation:\n",
        "  - 1: Clear, Few clouds, Partly cloudy.\n",
        "  - 2: Mist + Cloudy, Mist + Few clouds.\n",
        "  - 3: Light Snow, Light Rain, Thunderstorm, Scattered clouds.\n",
        "  - 4: Heavy Rain, Ice Pellets, Snow, Fog.\n",
        "- **temp:** Actual temperature in Celsius (normalized in the dataset).\n",
        "- **atemp:** Perceived or \"feeling\" temperature in Celsius.\n",
        "- **hum:** Humidity percentage.\n",
        "- **windspeed:** Wind speed.\n",
        "- **casual:** Count of casual users renting bikes.\n",
        "- **registered:** Count of registered users renting bikes.\n",
        "- **cnt:** Total count of rentals (sum of `casual` and `registered`).\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW4DK7tVHjqp"
      },
      "source": [
        "##  Reading and Understanding the Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gnNwmKYiHjqp"
      },
      "outputs": [],
      "source": [
        "# Supress Warnings\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cdwfKUuVHjqq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import statsmodels.api as sm\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn.metrics import r2_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "R9vzLLmSHjqq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "ffe2f915-76a0-4231-a5a5-4c5671283971"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'day.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-641467bcd018>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbike\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"day.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'day.csv'"
          ]
        }
      ],
      "source": [
        "bike = pd.DataFrame(pd.read_csv(\"day.csv\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmrmUf6yHjqq"
      },
      "outputs": [],
      "source": [
        "# Check the head of the dataset\n",
        "bike.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmfmfKCM1Hh9"
      },
      "source": [
        "## High-Level Approach\n",
        "\n",
        "\n",
        "After reviewing the data i want to highlight the approaches that i want to follow for this problemd:\n",
        "\n",
        "### 1. Data Understanding\n",
        "- Reviewed the dataset structure, types of variables, and checked for missing values.\n",
        "- Identified the target variable (`cnt`) and potential independent variables.\n",
        "\n",
        "### 2. Data Cleaning and Preprocessing\n",
        "- Dropped unnecessary columns such as `instant`.\n",
        "- Converted the `dteday` column into a datetime format for feature extraction.\n",
        "- Removed `casual` and `registered` to avoid data leakage as they sum up to `cnt`.\n",
        "\n",
        "### 3. Feature Engineering\n",
        "\n",
        "- Checked for highly correlated features like `temp` and `atemp` to avoid redundancy.\n",
        "- Encoded categorical variables such as `season` and `weathersit` using one-hot encoding.\n",
        "\n",
        "### 4. Exploratory Data Analysis (EDA)\n",
        "- Analyzed distributions of variables and visualized their relationships with the target variable.\n",
        "- Examine correlations to understand significant predictors and potential multicollinearity.\n",
        "\n",
        "### 5. Model Building\n",
        "- Split the data into training and testing sets.\n",
        "- Built a multiple linear regression model to predict bike demand (`cnt`).\n",
        "- Evaluated the model using metrics such as R-squared, Adjusted R-squared, and RMSE.\n",
        "\n",
        "### 6. Model Refinement\n",
        "- Iteratively removed insignificant predictors based on p-values.\n",
        "- Tested transformations and interactions for non-linear relationships.\n",
        "\n",
        "### 7. Insights and Recommendations\n",
        "- Interpreted the model coefficients to provide actionable business insights.\n",
        "- Suggested strategies to optimize bike-sharing operations based on the analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suHC8FFiHjqq"
      },
      "outputs": [],
      "source": [
        "# Check the descriptive information\n",
        "bike.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdYNOjGAHjqq"
      },
      "outputs": [],
      "source": [
        "bike.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oAPMRjW1Hh_"
      },
      "source": [
        "## Data Overview and Initial Inferences\n",
        "\n",
        "### Dataset Summary\n",
        "The dataset contains **730 entries** and **16 columns**, with no missing values. It includes a mix of categorical and numerical variables, as well as the target variable `cnt` (total bike rentals). Below is a summary of the dataset:\n",
        "\n",
        "1. **Structure:**\n",
        "   - **Total Rows:** 730\n",
        "   - **Total Columns:** 16\n",
        "   - **Data Types:** 11 integers, 4 floats, 1 object (date column)\n",
        "   - **No Missing Values:** The dataset is complete and ready for preprocessing.\n",
        "\n",
        "2. **Key Features:**\n",
        "   - **`instant`:** Record index (not a predictive feature, can be dropped).\n",
        "   - **`casual` an `registered`:** Breakdown of bike rentals; these s um up to `cnt`.\n",
        "   - **`temp` and `atemp`:** Temperature-related features (likely correlated).\n",
        "   - **`weathersit`:** Weather condition categories (1 = Clear, 2 = Mist, etc.).\n",
        "   - **`season`:** Encodes seasons (1 = Spring, 2 = Summer, etc.).\n",
        "\n",
        "---\n",
        "\n",
        "### Statistical Insights\n",
        "\n",
        "#### 1. **Target Variable (`cnt` - Total Rentals):**\n",
        "- **Mean Demand:** **4508** rentals per day.\n",
        "- **Range:** **22 (min)** to **8714 (max)**, indicating a wide variation in daily demand.\n",
        "- **Standard Deviation:** **1936**, suggesting significant variability.\n",
        "- The high variance indicates that external factors like season, weather, or working day might influence bike rentals.\n",
        "\n",
        "#### 2. **Temperature Features (`temp` and `atemp`):**\n",
        "- `temp` ranges from **2.42°C to 35.32°C**, while `atemp` (perceived temperature) ranges from **3.95°C to 42.04°C**.\n",
        "- Likely to exhibit multicollinearity; one feature might be redundant after correlation analysis.\n",
        "\n",
        "#### 3. **Humidity (`hum`) and Windspeed (`windspeed`):**\n",
        "- **Humidity:** Mean of **62.76%**, ranging up to **97.25%**.\n",
        "- **Windspeed:** Mean of **12.76**, with a maximum of **34.00**, suggesting that high winds might impact bike rentals.\n",
        "\n",
        "#### 4. **Categorical Features:**\n",
        "- **`season`:** Four categories (1 = Spring, 2 = Summer, 3 = Fall, 4 = Winter).\n",
        "- **`yr`:** Binary year indicator (0 = 2018, 1 = 2019).\n",
        "- **`mnth`:** 12 categories representing months.\n",
        "- **`holiday` and `workingday`:** Temporal variables capturing holidays and workdays.\n",
        "- **`weathersit`:** Encodes weather conditions, with categories ranging from clear to severe conditions.\n",
        "\n",
        "#### 5. **Bike Rental Breakdown (`casual` and `registered`):**\n",
        "- **Casual Users:** Mean of **849 rentals per day**, indicating irregular users.\n",
        "- **Registered Users:** Mean of **3658 rentals per day**, showing more consistent demand.\n",
        "- Registered users contribute significantly more to total rentals than casual users.\n",
        "\n",
        "---\n",
        "\n",
        "### Initial Observations\n",
        "- **Completeness:** No missing values in the dataset.\n",
        "- **Temporal Features:** Columns like  `weekday`, and `workingday` are essential for extracting temporal trends.\n",
        "- **Feature Redundancy:** Potential multicollinearity between `temp` and `atemp` should be addressed through correlation analysis.\n",
        "- **Target Variability:** Wide range in `cnt` suggests that external factors like weather and seasonality play a significant role in bike rentals.\n",
        "- **Key Predictors:** Features like `season`, `weathersit`, `workingday`, and `temp` are likely critical drivers of demand.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wnw_yjUl1HiA"
      },
      "source": [
        "## Conversion and Encoding of Categorical Variables\n",
        "Certain columns ( `season` , `weathersit` ) in the dataset use numeric values to represent categories. However, these numbers do not convey any inherent order, so treating them as numeric values could mislead the model. To make the data more interpretable and prepare it for machine learning, we convert these numeric codes into their actual string labels based on the data dictionary. After this, encoding will be applied to transform the categorical data into a format suitable for the model.\n",
        ".\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzXT5mqv1HiA"
      },
      "outputs": [],
      "source": [
        "# Mapping dictionaries based on the data dictionary\n",
        "season_mapping = {1: \"spring\", 2: \"summer\", 3: \"fall\", 4: \"winter\"}\n",
        "\n",
        "weathersit_mapping = {\n",
        "    1: \"Clear/Few clouds/Partly cloudy\",\n",
        "    2: \"Mist + Cloudy\",\n",
        "    3: \"Light Snow/Light Rain + Thunderstorm\",\n",
        "    4: \"Heavy Rain/Snow + Fog\"\n",
        "}\n",
        "\n",
        "# Converting numeric values to string labels\n",
        "bike[\"season\"] = bike[\"season\"].map(season_mapping)\n",
        "bike[\"weathersit\"] = bike[\"weathersit\"].map(weathersit_mapping)\n",
        "\n",
        "# Verify the conversion\n",
        "print(\"Unique values after conversion:\")\n",
        "print(\"Season:\", bike[\"season\"].unique())\n",
        "print(\"Weather Situation:\", bike[\"weathersit\"].unique())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoUPxjqB1HiB"
      },
      "outputs": [],
      "source": [
        "bike = pd.get_dummies(bike, columns=['season', 'weathersit'], dtype=int, drop_first=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N94MTIdy1HiB"
      },
      "source": [
        "### Interpretation of Encoded Categorical Features\n",
        "\n",
        "After preprocessing the dataset, several categorical variables were encoded to make them suitable for machine learning models. Below is the interpretation of the encoded values for each column:### 1. `season` (Seasons of the year)\n",
        "- `1000` → Spring\n",
        "- `0100` → Summer\n",
        "- `0010` → Fall\n",
        "- `0001` → Winter\n",
        "\n",
        "---\n",
        "\n",
        "### 2. `weathersit` (Weather situations)\n",
        "- `100` → Clear/Few clouds/Partly cloudy\n",
        "- `010` → Mist + Cloudy/Mist + Few clouds/Mist + Broken clouds\n",
        "- `001` → Light Snow/Light Rain + Thunderstorm/Scattered clouds\n",
        "n→e interpretability of the dataset.\n",
        "e interpretability of the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQW1IEJx1HiB"
      },
      "outputs": [],
      "source": [
        "bike.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Vtu-tCo1HiC"
      },
      "outputs": [],
      "source": [
        "bike.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8821zuCC1HiC"
      },
      "source": [
        "## Dropping the columns which are not required:\n",
        "The following columns were dropped to simplify the dataset and avoid redundancy:\n",
        "- `instant`, `mnth`, `dteday`, and `weekday`: These columns were dropped as they either represent irrelevant information (timestamps, categorical features) or are encoded in a more usable format.\n",
        "- `casual` and `registered`: These columns were dropped as the target variable `cnt` already captures the total number of rentals, which is the sum of `casual` and `registered`. Dropping them prevents redundancy and potential multicollinearity.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rnEugkz1HiC"
      },
      "outputs": [],
      "source": [
        "bike.drop(['instant','mnth','dteday','weekday','casual','registered'],axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oA8BO_Qa1HiC"
      },
      "outputs": [],
      "source": [
        "bike.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pXIX3ep1HiC"
      },
      "source": [
        "## Exploring the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0q25Ktc1HiC"
      },
      "outputs": [],
      "source": [
        "corr =bike.corr()\n",
        "plt.figure(figsize=(16,10))\n",
        "# Generate a heatmap\n",
        "sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', linewidths=0.5)\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzFiSmj71HiD"
      },
      "outputs": [],
      "source": [
        "bike.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LE4KTF-n1HiD"
      },
      "source": [
        "### Droping the highly correated column\n",
        "- column `temp` and `atemp` indicates high correlation hence am dropping the `temp` column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WcBtYRw1HiD"
      },
      "outputs": [],
      "source": [
        "bike.drop('temp',axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gT_2d4sE1HiD"
      },
      "outputs": [],
      "source": [
        "corr =bike.corr()\n",
        "plt.figure(figsize=(16,10))\n",
        "# Generate a heatmap\n",
        "sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', linewidths=0.5)\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWRUVYKX1HiD"
      },
      "source": [
        "## Data Preparation for model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VeWEJOj31HiD"
      },
      "outputs": [],
      "source": [
        "bike_train, bike_test = train_test_split(bike,train_size=0.7,test_size=0.3,random_state=55)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUiAQsWz1HiE"
      },
      "source": [
        "### Rescaling the dataset\n",
        "\n",
        "#### **Why Rescale Features with MinMaxScaler?**\n",
        "\n",
        "Rescaling features in multiple linear regression using MinMaxScaler is crucial for:\n",
        "\n",
        "* **Equalizing Feature Influence:** Prevents features with larger values from dominating the model.\n",
        "* **Improving Model Convergence:** Helps gradient-based optimization algorithms converge faster.\n",
        "* **Enhancing Interpretability:** Makes the coefficients of the regression model more comparable.\n",
        "\n",
        "**MinMaxScaler:**\n",
        "\n",
        "I have used MinMaxScaler to transform features to a specific range (0-1):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyp0iTyl1HiE"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqwJRxGb1HiE"
      },
      "outputs": [],
      "source": [
        "num_vars=['atemp','hum','windspeed','cnt']\n",
        "bike_train[num_vars]=scaler.fit_transform(bike_train[num_vars])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlxhvjZX1HiE"
      },
      "outputs": [],
      "source": [
        "bike_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zixg2AiL1HiE"
      },
      "outputs": [],
      "source": [
        "# splitting the data in to X_train and y_train data sets for model\n",
        "\n",
        "X_train=bike_train.drop('cnt',axis=1)\n",
        "y_train=bike_train['cnt']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LofiZH0q1HiE"
      },
      "source": [
        "### Feature selection using RFE\n",
        "\n",
        "#### Why Use RFE for Feature Selection?\n",
        "\n",
        "RFE (Recursive Feature Elimination) is a feature selection method used to select the most important features for a machine learning model. It works by recursively removing the least important features until the desired number of features is reached.\n",
        "\n",
        "**Benefits of using RFE:**\n",
        "\n",
        "* **Improved Model Accuracy:** By selecting only the most relevant features, RFE can help to improve the accuracy of the model by reducing noise and overfitting.\n",
        "* **Reduced Model Complexity:** RFE simplifies the model by reducing the number of features, making it easier to interpret and understand.\n",
        "* **Faster Training Time:** With fewer features, the model can be trained faster.\n",
        "\n",
        "Am going to use RFE to select 10 features and from there i will review the features and start eliminating the manually until there no multi colineary and acceptable model accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "locxQrHz1HiE"
      },
      "outputs": [],
      "source": [
        "lm= LinearRegression()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-vFR6Dk1HiF"
      },
      "outputs": [],
      "source": [
        "# Perform RFE\n",
        "rfe = RFE(lm, n_features_to_select=10)  # Adjust `n_features_to_select` as needed\n",
        "rfe = rfe.fit(X_train, y_train)\n",
        "# Get the selected features\n",
        "selected_features = X_train.columns[rfe.support_]\n",
        "print(\"Selected Features:\", selected_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3FKLi-KS1HiF"
      },
      "outputs": [],
      "source": [
        "# Subset X_train to include only the selected features\n",
        "X_train_rfe = X_train[selected_features]\n",
        "# Add constant for statsmodels OLS\n",
        "X_train_rfe = sm.add_constant(X_train_rfe)\n",
        "# Train the final OLS model with selected features\n",
        "ols_model = sm.OLS(y_train, X_train_rfe).fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7I9O4By1HiF"
      },
      "outputs": [],
      "source": [
        "ols_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7A1FrpwC1HiF"
      },
      "outputs": [],
      "source": [
        "# Function to calculate VIF\n",
        "def calculate_vif(X):\n",
        "    vif_data = pd.DataFrame()\n",
        "    vif_data['Feature'] = X.columns\n",
        "    vif_data['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "    return vif_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBngmyNl1HiF"
      },
      "outputs": [],
      "source": [
        "# Exclude the constant term when calculating VIF\n",
        "X_train_no_const = X_train_rfe.drop('const', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZptygQP1HiO"
      },
      "outputs": [],
      "source": [
        "# Calculate VIF\n",
        "vif_results = calculate_vif(X_train_no_const)\n",
        "print(vif_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_S99vOa41HiO"
      },
      "source": [
        "### Drop `weathersit_Clear/Few clouds/Partly cloudy ` column\n",
        "\n",
        "\n",
        "\n",
        "In the initial model, the `weathersit_Clear/Few clouds/Partly cloudy` feature was dropped. This was done to address potential multicollinearity issues and avoid the dummy variable trap.\n",
        "\n",
        "**Dummy Variable Trap:** When using dummy variables for categorical features, one category is typically dropped as a reference category. This prevents perfect multicollinearity, which can lead to inflated VIF values and unstable model coefficients.\n",
        "\n",
        "By dropping `weathersit_Clear/Few clouds/Partly cloudy`, the model avoids the dummy variable trap and maintains the interpretability of the other weather situation features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AriMnZYB1HiO"
      },
      "outputs": [],
      "source": [
        "X_train_rfe.drop('weathersit_Clear/Few clouds/Partly cloudy',axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWHaF4-v1HiO"
      },
      "outputs": [],
      "source": [
        "# Add constant for statsmodels OLS\n",
        "X_train_rfe = sm.add_constant(X_train_rfe)\n",
        "\n",
        "# Train the final OLS model with selected features\n",
        "ols_model_1 = sm.OLS(y_train, X_train_rfe).fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFuRmrIP1HiO"
      },
      "outputs": [],
      "source": [
        "ols_model_1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z04NybRQ1HiP"
      },
      "outputs": [],
      "source": [
        "# Exclude the constant term when calculating VIF\n",
        "X_train_no_const = X_train_rfe.drop('const', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ah_byxRI1HiP"
      },
      "outputs": [],
      "source": [
        "# Calculate VIF\n",
        "vif_results = calculate_vif(X_train_no_const)\n",
        "print(vif_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GR4ai6sU1HiP"
      },
      "outputs": [],
      "source": [
        "X_train_rfe.drop('hum',axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lII3iUra1HiP"
      },
      "outputs": [],
      "source": [
        "# Add constant for statsmodels OLS\n",
        "X_train_rfe = sm.add_constant(X_train_rfe)\n",
        "\n",
        "# Train the final OLS model with selected features\n",
        "ols_model_2 = sm.OLS(y_train, X_train_rfe).fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fT9q20jV1HiQ"
      },
      "outputs": [],
      "source": [
        "ols_model_2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgMVAxVe1HiQ"
      },
      "outputs": [],
      "source": [
        "# Exclude the constant term when calculating VIF\n",
        "X_train_no_const = X_train_rfe.drop('const', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FT9STGEu1HiQ"
      },
      "outputs": [],
      "source": [
        "# Calculate VIF\n",
        "vif_results = calculate_vif(X_train_no_const)\n",
        "print(vif_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVzQrLGt1HiR"
      },
      "outputs": [],
      "source": [
        "selected_features=vif_results['Feature'].to_list()\n",
        "print(selected_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m75hL3tZ1HiR"
      },
      "outputs": [],
      "source": [
        "# Subset X_train to include only the selected features\n",
        "X_train_rfe = X_train[selected_features]\n",
        "\n",
        "# Add constant for statsmodels OLS\n",
        "X_train_rfe = sm.add_constant(X_train_rfe)\n",
        "\n",
        "# Train the final OLS model with selected features\n",
        "ols_model_3 = sm.OLS(y_train, X_train_rfe).fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNZvZ5Nf1HiR"
      },
      "outputs": [],
      "source": [
        "ols_model_3.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNkX3ve01HiS"
      },
      "outputs": [],
      "source": [
        "y_train_pred= ols_model_3.predict(X_train_rfe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hasxCciC1HiS"
      },
      "outputs": [],
      "source": [
        "# Plot the histogram of the error terms\n",
        "fig = plt.figure()\n",
        "sns.distplot((y_train - y_train_pred), bins = 20)\n",
        "fig.suptitle('Error Terms', fontsize = 20)\n",
        "plt.xlabel('Errors', fontsize = 18)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWBQyj-o1HiS"
      },
      "outputs": [],
      "source": [
        "num_vars=['atemp','hum','windspeed','cnt']\n",
        "\n",
        "bike_test[num_vars]=scaler.fit_transform(bike_test[num_vars])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4v4YlpC1HiT"
      },
      "outputs": [],
      "source": [
        "bike_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGI-Woko1HiT"
      },
      "outputs": [],
      "source": [
        "X_test=bike_test.drop('cnt',axis=1)\n",
        "\n",
        "y_test=bike_test['cnt']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyI0LSVg1HiT"
      },
      "outputs": [],
      "source": [
        "\n",
        "X_test_rfe=sm.add_constant(X_test[selected_features])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Us4AD0UL1HiT"
      },
      "outputs": [],
      "source": [
        "y_test_pred= ols_model_3.predict(X_test_rfe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cf-4XcNK1HiU"
      },
      "outputs": [],
      "source": [
        "# Plotting y_test and y_pred to understand the spread\n",
        "fig = plt.figure()\n",
        "plt.scatter(y_test, y_test_pred,alpha=.5)\n",
        "fig.suptitle('y_test vs y_pred', fontsize = 20)\n",
        "plt.xlabel('y_test', fontsize = 18)\n",
        "plt.ylabel('y_pred', fontsize = 16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEbbfKQM1HiU"
      },
      "outputs": [],
      "source": [
        "# Calculate R²\n",
        "r2 = r2_score(y_test, y_test_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dlbkoxI1HiU"
      },
      "outputs": [],
      "source": [
        "# Get the number of observations and predictors\n",
        "n = len(y_test)  # Number of observations\n",
        "p = X_test_rfe.shape[1]  # Number of predictors (from the test set)\n",
        "\n",
        "# Calculate Adjusted R²\n",
        "adjusted_r2 = 1 - ((1 - r2) * (n - 1) / (n - p - 1))\n",
        "\n",
        "print(f\"R²: {r2}\")\n",
        "print(f\"Adjusted R²: {adjusted_r2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQdQtqDE1HiU"
      },
      "outputs": [],
      "source": [
        "# Calculate residuals\n",
        "residuals = y_test - y_test_pred\n",
        "\n",
        "# Residuals vs. Fitted Values Plot\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.scatter(y_test_pred, residuals, alpha=0.7, edgecolor='k')\n",
        "plt.axhline(0, color='red', linestyle='--', linewidth=2)\n",
        "plt.title('Residuals vs. Fitted Values', fontsize=16)\n",
        "plt.xlabel('Fitted Values (y_pred)', fontsize=14)\n",
        "plt.ylabel('Residuals (y_test - y_pred)', fontsize=14)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suK9LOur1HiV"
      },
      "outputs": [],
      "source": [
        "# Histogram of Residuals\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.histplot(residuals, kde=True, color='blue', bins=30)\n",
        "plt.title('Histogram of Residuals', fontsize=16)\n",
        "plt.xlabel('Residuals', fontsize=14)\n",
        "plt.ylabel('Frequency', fontsize=14)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yuELbntf1HiV"
      },
      "outputs": [],
      "source": [
        "# Q-Q Plot\n",
        "sm.qqplot(residuals, line='45', fit=True)\n",
        "plt.title('Q-Q Plot of Residuals', fontsize=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final Conclusion for Bike Sharing Demand Prediction\n",
        "\n",
        "#### Business Context:\n",
        "BikeIndia, a US bike-sharing provider, aims to recover from revenue losses caused by the COVID-19 pandemic by understanding the factors influencing bike demand. The goal is to prepare for post-pandemic market conditions and optimize business strategies to meet customer demand and maximize profits.\n",
        "\n",
        "#### Model Performance:\n",
        "1. **Train Data**:\n",
        "   - **R-squared**: 0.828 (82.8% of the variance in bike demand (`cnt`) is explained by the model).\n",
        "   - **Adjusted R-squared**: 0.825 (adjusted for the number of predictors, the model explains 82.5% of the variance).\n",
        "   - **F-statistic**: 300.6 (p-value = 8.93e-186), indicating the model is statistically significant.\n",
        "   - All predictors are statistically significant (p-values < 0.05), with `yr` (year) and `atemp` (feeling temperature) having the strongest positive impact on bike demand.\n",
        "\n",
        "2. **Test Data**:\n",
        "   - **R-squared**: 0.746 (74.6% of the variance in bike demand is explained on the test data).\n",
        "   - **Adjusted R-squared**: 0.735 (adjusted for the number of predictors, the model explains 73.5% of the variance).\n",
        "   - The model generalizes well to unseen data, though there is a slight drop in performance compared to the training data, which is expected.\n",
        "\n",
        "---\n",
        "\n",
        "#### Residual Analysis:\n",
        "1. **Residuals vs. Fitted Values Plot**:\n",
        "   - The residuals are randomly scattered around zero, indicating no clear pattern or heteroscedasticity. This suggests that the linearity assumption is satisfied.\n",
        "\n",
        "2. **Q-Q Plot of Residuals**:\n",
        "   - The residuals deviate from the theoretical quantiles at the tails, indicating non-normality. This is consistent with the high **Jarque-Bera** and **Omnibus** test results from the model summary.\n",
        "\n",
        "3. **Histogram of Residuals**:\n",
        "   - The residuals are slightly left-skewed and have heavier tails than a normal distribution, which aligns with the **Skew** (-0.601) and **Kurtosis** (5.092) values.\n",
        "\n",
        "---\n",
        "\n",
        "#### Key Observations:\n",
        "- The model performs well on both training and test data, with high R-squared values and statistically significant predictors.\n",
        "- Residual diagnostics indicate that the linearity assumption is satisfied, but the residuals are not perfectly normally distributed. This is common in real-world datasets and may not severely impact the model's predictive power.\n",
        "- The drop in R-squared from training to test data (0.828 to 0.746) suggests slight overfitting, but the model still generalizes reasonably well.\n",
        "\n",
        "---\n",
        "\n",
        "#### Significant Predictors of Bike Demand:\n",
        "1. **Positive Impact**:\n",
        "   - `yr` (Year): Bike demand increases over time, indicating a growing trend in bike-sharing usage.\n",
        "   - `atemp` (Feeling Temperature): Higher perceived temperatures lead to increased bike rentals.\n",
        "   - `season_winter`: Winter season shows a slight positive impact on bike demand compared to spring.\n",
        "\n",
        "2. **Negative Impact**:\n",
        "   - `holiday`: Bike demand decreases on holidays.\n",
        "   - `windspeed`: Higher wind speeds reduce bike rentals.\n",
        "   - `season_spring`: Spring season has a negative impact on bike demand compared to other seasons.\n",
        "   - `weathersit`: Adverse weather conditions (e.g., Light Snow, Light Rain, Thunderstorm) significantly reduce bike demand.\n",
        "\n",
        "---\n",
        "\n",
        "#### Recommendations for BikeIndia:\n",
        "1. **Business Strategy**:\n",
        "   - Focus on marketing and promotions during favorable weather conditions (e.g., clear skies, moderate temperatures) to maximize bike rentals.\n",
        "   - Offer incentives or discounts during holidays and adverse weather conditions to attract customers.\n",
        "   - Plan for increased bike availability during peak seasons (e.g., winter) and years with expected growth in demand.\n",
        "\n",
        "2. **Model Improvement**:\n",
        "   - Consider transforming the dependent variable (`cnt`) or predictors to address the non-normality of residuals.\n",
        "   - Explore regularization techniques (e.g., Ridge or Lasso regression) to reduce overfitting and improve generalization.\n",
        "   - Investigate interaction terms or polynomial features to capture non-linear relationships.\n",
        "\n",
        "---\n",
        "\n",
        "#### Final Remarks:\n",
        "The multiple linear regression model provides a strong fit for the data, explaining a significant portion of the variance in bike demand. While the residuals exhibit slight non-normality, the model's predictive performance on test data is satisfactory. The insights from this model can help BikeIndia optimize its business strategies to meet customer demand and achieve revenue growth in the post-pandemic market.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "1-nnv1Q75sM_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final Regression Equation for Bike Demand Prediction\n",
        "\n",
        "The demand for shared bikes (`cnt`) can be predicted using the following equation:\n",
        "\n",
        "cnt = 0.2835 + 0.2415 * **`yr`** - 0.1023 * holiday + 0.4247 * atemp - 0.0952 * windspeed - 0.1485 * season_spring + 0.0385 * season_winter - 0.3180 * weathersit_Light_Snow - 0.0691 * weathersit_Mist_Cloudy\n",
        "\n",
        "#### Explanation of Terms:\n",
        "- **Intercept (0.2835)**: Baseline bike demand when all predictors are zero.\n",
        "- **yr (0.2415)**: Bike demand increases by 0.2415 units for each year (2019 compared to 2018).\n",
        "- **holiday (-0.1023)**: Bike demand decreases by 0.1023 units on holidays.\n",
        "- **atemp (0.4247)**: Bike demand increases by 0.4247 units for each unit increase in feeling temperature.\n",
        "- **windspeed (-0.0952)**: Bike demand decreases by 0.0952 units for each unit increase in wind speed.\n",
        "- **season_spring (-0.1485)**: Bike demand decreases by 0.1485 units during spring compared to the reference season.\n",
        "- **season_winter (0.0385)**: Bike demand increases by 0.0385 units during winter compared to the reference season.\n",
        "- **weathersit_Light Snow/Light Rain + Thunderstorm (-0.3180)**: Bike demand decreases by 0.3180 units during light snow, light rain, or thunderstorms compared to clear weather.\n",
        "- **weathersit_Mist + Cloudy (-0.0691)**: Bike demand decreases by 0.0691 units during misty or cloudy weather compared to clear weather.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "l8BWRJ736RSV"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "Bike Sharing : Multiple Linear Regression",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 789011,
          "sourceId": 1355226,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 29980,
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}